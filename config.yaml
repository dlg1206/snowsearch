# Options for snowballing technique
# REQUIRED
snowball:
  # Upper limit for the number of papers to initially start with to download from OpenAlex and get citations for
  # Leave blank for no upper limit
  seed_paper_limit: 10

  # Number of rounds of snowballing to do
  # REQUIRED
  rounds: 3

  # For each round, the upper limit of the number of papers to snowball (fetch citation details for)
  # Leave blank for no upper limit
  papers_per_round: 3

  # Minimum similarity score between the natural language query and title / abstract.
  # Must be [-1,1], but 0.4 is recommended.
  # Increasing will reduce the number of valid papers, potentially limiting the snowball pool.
  # Decreasing will increase the number of valid papers, potentially adding a lot of noise to the pool
  # It is recommended to keep this value somewhat low to cast a wide net, after which the score can be
  # increased when ranking papers
  # REQUIRED
  min_similarity_score: .4

# Options for generating Elastic search query for OpenAlex
# REQUIRED
query_generation:
  # LLM Options
  agent:
    # Host of an ollama server, will default to 'localhost'
    # Useful if ollama server is not running locally, ie running on a remote host with more resources available
    # Superseded by the OLLAMA_HOST env variable
    # Ignored if the OPENAI_API_KEY env variable is set, in which case the OpenAI API is used
    # ollama_host:

    # Port of an ollama server, will default to '11434'
    # Useful if ollama server is not running locally, ie running on a remote host with more resources available
    # Superseded by the OLLAMA_PORT env variable
    # Ignored if the OPENAI_API_KEY env variable is set, in which case the OpenAI API is used
    # ollama_port:

    # Model to use for parsing natural language paper search into findpapers syntax
    # If using ollama (default), search for desired models here: https://ollama.com/search
    # If using OpenAI, search for desired models here: https://platform.openai.com/docs/models
    # REQUIRED
    model: llama3

    # If using ollama, specify a tag model to use, will default to 'latest'
    tag: 8b

# Options for ranking papers
# REQUIRED
abstract_ranking:
  # LLM Options
  agent:
    # Host of an ollama server, will default to 'localhost'
    # Useful if ollama server is not running locally, ie running on a remote host with more resources available
    # Superseded by the OLLAMA_HOST env variable
    # Ignored if the OPENAI_API_KEY env variable is set, in which case the OpenAI API is used
    # ollama_host:

    # Port of an ollama server, will default to '11434'
    # Useful if ollama server is not running locally, ie running on a remote host with more resources available
    # Superseded by the OLLAMA_PORT env variable
    # Ignored if the OPENAI_API_KEY env variable is set, in which case the OpenAI API is used
    # ollama_port:

    # Model to use for parsing natural language paper search into findpapers syntax
    # If using ollama (default), search for desired models here: https://ollama.com/search
    # If using OpenAI, search for desired models here: https://platform.openai.com/docs/models
    # REQUIRED
    model: llama3

    # If using ollama, specify a tag model to use, will default to 'latest'
    tag: 8b

  # Context window of selected model
  # REQUIRED
  context_window: 8000

  # Average tokens per word, will default to 1.2
  # tokens_per_word:

  # Minimum similarity score between the prompt and abstract, must be [-1,1], but 0.4 recommended
  # Lowering this value will increase the number of papers included in the LLM ranking
  # It is recommended to keep this value relatively high so rounds aren't wasted on irrelevant papers
  # REQUIRED
  min_abstract_score: .6

  # Number of papers to rank
  # All abstracts will need to fit inside context window for final ranking.
  # For reference, 1 abstract ~= 250 - 500 tokens
  # REQUIRED
  top_n_papers: 10

# Config for OpenAlex API
# https://docs.openalex.org/
openalex:
  # Optional email to use for 'polite pool' for better access
  # Queries are 10x faster if an email is provided
  # https://docs.openalex.org/how-to-use-the-api/rate-limits-and-authentication#the-polite-pool
  # email:

# Config for Grobid
# https://github.com/kermitt2/grobid
grobid:
  # Config for grobid python client
  # https://github.com/kermitt2/grobid-client-python?tab=readme-ov-file#default-configuration
  client_config:
    # Host and port of a grobid server, will default to 'localhost:8070'
    # Useful if grobid server is not running locally, ie running on a remote host with more resources available
    # Superseded by the GROBID_SERVER env variable
    # grobid_server:

    # Thread pool size.
    # Tune carefully: a large batch size will result in the data being written less frequently
    # Default is 1000
    # batch_size:

    # Wait time when server is busy (seconds)
    # Default is 5
    # sleep_time:

    # Client-side timeout (seconds)
    # Default is 180
    # timeout:

    # List of TEI XML elements for which GROBID should extract coordinates (bounding boxes), ie x y location in pdf.
    # Defaults are
    # - persName
    # - figure
    # - ref
    # - biblStruct
    # - formula
    # - s
    # coordinates:

  # Max number of requests allowed to be made to the grobid server at a time
  # Default is 1
  # max_grobid_requests:

  # Max number of PDFs to allowed to download at the same time
  # Default is 10
  # max_concurrent_downloads:

  # Max number of PDFs to be downloaded locally at one time
  # Default is 100
  # max_local_pdfs: