# Options for configuring LLM agents
# todo - different agents for nl -> fp query and abstract ranking
agent:
  # Host of an ollama server, will default to 'localhost'
  # Useful if ollama server is not running locally, ie running on a remote host with more resources available
  # Superseded by the OLLAMA_HOST env variable
  # Ignored if the OPENAI_API_KEY env variable is set, in which case the OpenAI API is used
  # ollama_host:

  # Port of an ollama server, will default to '11434'
  # Useful if ollama server is not running locally, ie running on a remote host with more resources available
  # Superseded by the OLLAMA_PORT env variable
  # Ignored if the OPENAI_API_KEY env variable is set, in which case the OpenAI API is used
  # ollama_port:

  # Model to use for parsing natural language paper search into findpapers syntax
  # If using ollama (default), search for desired models here: https://ollama.com/search
  # If using OpenAI, search for desired models here: https://platform.openai.com/docs/models
  model: llama3

  # If using ollama, specify a tag model to use, will default to 'latest'
  tag: 8b

# Options for findpapers
# https://github.com/jonatasgrosman/findpapers
# Set FINDPAPERS_SCOPUS_API_TOKEN and FINDPAPERS_IEEE_API_TOKEN in the .env file if available
findpapers:
  # A lower bound (inclusive) date that will be used to filter the search results.
  # Following the pattern YYYY-MM-DD. E.g. 2020-12-31
  # since:

  # An upper bound (inclusive) date that will be used to filter the search results.
  # Following the pattern YYYY-MM-DD. E.g. 2020-12-31
  # until:

  # The max number of papers to collect
  # limit: 10

  # The max number of papers to collect per each database
  # limit_per_database:

  # List of databases where the search should be performed, if not specified all databases will be used
  # To access IEEE and Scopus, an API key must be used
  #   IEEE (https://developer.ieee.org) and set FINDPAPERS_SCOPUS_API_TOKEN env var
  #   Scopus (https://dev.elsevier.com) and set FINDPAPERS_IEEE_API_TOKEN env var
  # options:
  # - ~~acm~~ ACM is an option but not working, see https://github.com/jonatasgrosman/findpapers/issues/6
  # - arxiv
  # - biorxiv
  # - ieee
  # - medrxiv
  # - pubmed
  # - scopus
  # databases:

  # List of publication types to filter when searching, if not specified all the publication types will be collected
  # options:
  # - journal
  # - conference
  # - proceedings
  # - book
  # - other
  # publication_types:

  # Proxy URL that can be used during requests
  # Intended for institution proxies (like a campus library) to access protected docs
  # proxy:

# Config for OpenAlex API
# https://docs.openalex.org/
openalex:
  # Optional email to use for 'polite pool' for better access
  # https://docs.openalex.org/how-to-use-the-api/rate-limits-and-authentication#the-polite-pool
  # email:

grobid:
  # https://github.com/kermitt2/grobid-client-python?tab=readme-ov-file#default-configuration

  # Host and port of a grobid server, will default to 'localhost:8070'
  # Useful if grobid server is not running locally, ie running on a remote host with more resources available
  # Superseded by the GROBID_SERVER env variable
  # grobid_server:

  # Thread pool size.
  # Tune carefully: a large batch size will result in the data being written less frequently
  # Default is 1000
  # batch_size:

  # Wait time when server is busy (seconds)
  # Default is 5
  # sleep_time:

  # Client-side timeout (seconds)
  # Default is 180
  # timeout:

  # List of TEI XML elements for which GROBID should extract coordinates (bounding boxes), ie x y location in pdf.
  # Defaults are
  # - persName
  # - figure
  # - ref
  # - biblStruct
  # - formula
  # - s
  # coordinates: